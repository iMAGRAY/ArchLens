/// Export functionality - generates various analysis reports
use std::path::Path;
use std::fs;
use std::collections::HashMap;

/// Generates an AI-readable compact analysis report
/// 
/// This function creates a comprehensive but concise analysis report that includes:
/// - Project statistics (files, lines of code, complexity)
/// - Critical issues detection
/// - Architectural pattern recognition
/// - Project structure overview
/// - Key modules identification
/// - Quality metrics calculation
/// - Actionable recommendations
/// 
/// # Arguments
/// 
/// * `project_path` - Path to the project root directory to analyze
/// 
/// # Returns
/// 
/// A `Result` containing the formatted analysis report as a string, or an error message.
/// 
/// # Examples
/// 
/// ```rust
/// use archlens::cli::export::generate_ai_compact;
/// 
/// let report = generate_ai_compact("/path/to/project")?;
/// println!("{}", report);
/// ```
/// 
/// # Report Format
/// 
/// The generated report follows a structured markdown format with:
/// - Header with project information and analysis metadata
/// - Quick statistics section
/// - Critical issues (if any)
/// - Architectural patterns detected
/// - Project structure tree
/// - Key modules listing
/// - Recommendations for improvement
/// - Quality metrics summary
pub fn generate_ai_compact(project_path: &str) -> std::result::Result<String, String> {
    if !Path::new(project_path).exists() {
        return Err("Path does not exist".to_string());
    }
    
    let mut output = String::new();
    
    // Header
    output.push_str("# ğŸ—ï¸ AI COMPACT ARCHITECTURE ANALYSIS\n\n");
    output.push_str(&format!("**Project:** {}\n", project_path));
    output.push_str(&format!("**Analysis date:** {}\n", chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC")));
    output.push_str(&format!("**Analysis ID:** {}\n\n", uuid::Uuid::new_v4()));
    
    // Quick statistics
    let stats = collect_basic_stats(project_path)?;
    output.push_str("## ğŸ“Š QUICK STATISTICS\n");
    output.push_str(&format!("- **Total files:** {}\n", stats.total_files));
    output.push_str(&format!("- **Lines of code:** {}\n", stats.total_lines));
    output.push_str(&format!("- **File types:** {}\n", stats.file_types.len()));
    output.push_str(&format!("- **Components:** {}\n", stats.components));
    output.push_str(&format!("- **Connections:** {}\n", stats.connections));
    output.push_str("\n");
    
    // Critical issues
    let issues = analyze_critical_issues(project_path)?;
    if !issues.is_empty() {
        output.push_str("## ğŸš¨ CRITICAL ISSUES\n");
        for issue in issues {
            output.push_str(&format!("- **{}:** {}\n", issue.severity, issue.description));
        }
        output.push_str("\n");
    }
    
    // Architectural patterns
    let patterns = detect_architectural_patterns(project_path)?;
    if !patterns.is_empty() {
        output.push_str("## ğŸ›ï¸ ARCHITECTURAL PATTERNS\n");
        for pattern in patterns {
            output.push_str(&format!("- **{}:** {} (confidence: {}%)\n", 
                                   pattern.name, pattern.description, pattern.confidence));
        }
        output.push_str("\n");
    }
    
    // Project structure
    let structure = analyze_project_structure(project_path)?;
    output.push_str("## ğŸ“ PROJECT STRUCTURE\n");
    output.push_str(&format!("```\n{}\n```\n\n", structure));
    
    // Key modules
    let modules = analyze_key_modules(project_path)?;
    if !modules.is_empty() {
        output.push_str("## ğŸ”§ KEY MODULES\n");
        for module in modules {
            output.push_str(&format!("- **{}** ({}): {}\n", 
                                   module.name, module.category, module.description));
        }
        output.push_str("\n");
    }
    
    // Recommendations
    let recommendations = generate_recommendations(project_path)?;
    if !recommendations.is_empty() {
        output.push_str("## ğŸ’¡ RECOMMENDATIONS\n");
        for rec in recommendations {
            output.push_str(&format!("- **{}:** {}\n", rec.priority, rec.description));
        }
        output.push_str("\n");
    }
    
    // Quality metrics
    let quality = calculate_quality_metrics(project_path)?;
    output.push_str("## ğŸ“ˆ QUALITY METRICS\n");
    output.push_str(&format!("- **Maintainability index:** {}/100\n", quality.maintainability));
    output.push_str(&format!("- **Cyclomatic complexity:** {}\n", quality.complexity));
    output.push_str(&format!("- **Documentation coverage:** {}%\n", quality.documentation_coverage));
    output.push_str(&format!("- **Tech debt:** {}\n", quality.tech_debt));
    output.push_str("\n");
    
    output.push_str("---\n");
    output.push_str("*Generated by ArchLens AI Compact Export*\n");
    
    Ok(output)
}

// Helper structures
#[derive(Debug)]
struct CompactStats {
    total_files: usize,
    total_lines: usize,
    file_types: HashMap<String, usize>,
    components: usize,
    connections: usize,
}

#[derive(Debug)]
struct CriticalIssue {
    severity: String,
    description: String,
}

#[derive(Debug)]
struct ArchitecturalPattern {
    name: String,
    description: String,
    confidence: u8,
}

#[derive(Debug)]
struct KeyModule {
    name: String,
    category: String,
    description: String,
}

#[derive(Debug)]
struct Recommendation {
    priority: String,
    description: String,
}

#[derive(Debug)]
struct QualityMetrics {
    maintainability: u8,
    complexity: u8,
    documentation_coverage: u8,
    tech_debt: String,
}

// Helper functions
fn collect_basic_stats(project_path: &str) -> std::result::Result<CompactStats, String> {
    use super::stats;
    
    let project_stats = stats::get_project_stats(project_path)?;
    let components = project_stats.file_types.values().sum::<usize>();
    let connections = (components * 2) / 3;
    
    Ok(CompactStats {
        total_files: project_stats.total_files,
        total_lines: project_stats.total_lines,
        file_types: project_stats.file_types,
        components,
        connections,
    })
}

fn analyze_critical_issues(project_path: &str) -> std::result::Result<Vec<CriticalIssue>, String> {
    let mut issues = Vec::new();
    
    let large_files = find_large_files(project_path)?;
    if !large_files.is_empty() {
        issues.push(CriticalIssue {
            severity: "HIGH".to_string(),
            description: format!("Found {} large files (>500 lines)", large_files.len()),
        });
    }
    
    Ok(issues)
}

fn detect_architectural_patterns(project_path: &str) -> std::result::Result<Vec<ArchitecturalPattern>, String> {
    let mut patterns = Vec::new();
    
    if has_modular_structure(project_path)? {
        patterns.push(ArchitecturalPattern {
            name: "Modular".to_string(),
            description: "Modular architecture".to_string(),
            confidence: 90,
        });
    }
    
    Ok(patterns)
}

fn analyze_project_structure(project_path: &str) -> std::result::Result<String, String> {
    let mut structure = String::new();
    let path = Path::new(project_path);
    
    analyze_directory(path, &mut structure, 0)?;
    Ok(structure)
}

fn analyze_directory(dir_path: &Path, structure: &mut String, depth: usize) -> std::result::Result<(), String> {
    let entries = fs::read_dir(dir_path)
        .map_err(|e| format!("Failed to read directory: {}", e))?;
        
    for entry in entries {
        let entry = entry.map_err(|e| format!("Failed to read entry: {}", e))?;
        let path = entry.path();
        let name = path.file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("unknown");
            
        if should_skip_directory(name) {
            continue;
        }
        
        let indent = "  ".repeat(depth);
        
        if path.is_dir() {
            structure.push_str(&format!("{}ğŸ“ {}/\n", indent, name));
            if depth < 3 {
                analyze_directory(&path, structure, depth + 1)?;
            }
        } else if is_important_file(name) {
            structure.push_str(&format!("{}ğŸ“„ {}\n", indent, name));
        }
    }
    
    Ok(())
}

fn analyze_key_modules(project_path: &str) -> std::result::Result<Vec<KeyModule>, String> {
    let mut modules = Vec::new();
    
    if Path::new(&format!("{}/Cargo.toml", project_path)).exists() {
        modules.push(KeyModule {
            name: "Rust Project".to_string(),
            category: "Backend".to_string(),
            description: "Main Rust project".to_string(),
        });
    }
    
    if Path::new(&format!("{}/src/main.rs", project_path)).exists() {
        modules.push(KeyModule {
            name: "Main Entry".to_string(),
            category: "Core".to_string(),
            description: "Application entry point".to_string(),
        });
    }
    
    Ok(modules)
}

fn generate_recommendations(project_path: &str) -> std::result::Result<Vec<Recommendation>, String> {
    let mut recommendations = Vec::new();
    
    let large_files = find_large_files(project_path)?;
    if !large_files.is_empty() {
        recommendations.push(Recommendation {
            priority: "HIGH".to_string(),
            description: "Split large files into smaller modules".to_string(),
        });
    }
    
    Ok(recommendations)
}

fn calculate_quality_metrics(project_path: &str) -> std::result::Result<QualityMetrics, String> {
    let maintainability = estimate_maintainability(project_path)?;
    let complexity = estimate_complexity(project_path)?;
    let documentation_coverage = estimate_documentation_coverage(project_path)?;
    let tech_debt = estimate_tech_debt(project_path)?;
    
    Ok(QualityMetrics {
        maintainability,
        complexity,
        documentation_coverage,
        tech_debt,
    })
}

fn find_large_files(project_path: &str) -> std::result::Result<Vec<String>, String> {
    let mut large_files = Vec::new();
    let path = Path::new(project_path);
    
    scan_for_large_files(path, &mut large_files)?;
    Ok(large_files)
}

fn scan_for_large_files(dir: &Path, large_files: &mut Vec<String>) -> std::result::Result<(), String> {
    let entries = fs::read_dir(dir)
        .map_err(|e| format!("Failed to read directory: {}", e))?;
        
    for entry in entries {
        let entry = entry.map_err(|e| format!("Failed to read entry: {}", e))?;
        let path = entry.path();
        
        if path.is_dir() {
            let name = path.file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("");
                
            if !should_skip_directory(name) {
                scan_for_large_files(&path, large_files)?;
            }
        } else if path.is_file() {
            let name = path.file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("");
                
            if is_code_file(path.extension().and_then(|e| e.to_str()).unwrap_or("")) {
                if let Ok(content) = fs::read_to_string(&path) {
                    let line_count = content.lines().count();
                    if line_count > 500 {
                        large_files.push(format!("{} ({} lines)", name, line_count));
                    }
                }
            }
        }
    }
    
    Ok(())
}

fn has_modular_structure(project_path: &str) -> std::result::Result<bool, String> {
    let src_path_str = format!("{}/src", project_path);
    let src_path = Path::new(&src_path_str);
    if !src_path.exists() {
        return Ok(false);
    }
    
    let mut module_count = 0;
    let entries = fs::read_dir(src_path)
        .map_err(|e| format!("Failed to read src directory: {}", e))?;
        
    for entry in entries {
        let entry = entry.map_err(|e| format!("Failed to read entry: {}", e))?;
        let path = entry.path();
        
        if path.is_dir() {
            let name = path.file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("");
                
            if !should_skip_directory(name) {
                module_count += 1;
            }
        }
    }
    
    Ok(module_count >= 3)
}

fn estimate_maintainability(project_path: &str) -> std::result::Result<u8, String> {
    let mut score = 100u8;
    
    let large_files = find_large_files(project_path)?;
    if !large_files.is_empty() {
        score = score.saturating_sub(large_files.len() as u8 * 5);
    }
    
    Ok(score.max(30))
}

fn estimate_complexity(project_path: &str) -> std::result::Result<u8, String> {
    let mut complexity = 5u8;
    
    let large_files = find_large_files(project_path)?;
    complexity += large_files.len() as u8;
    
    Ok(complexity.min(20))
}

fn estimate_documentation_coverage(project_path: &str) -> std::result::Result<u8, String> {
    let mut coverage = 50u8;
    
    if Path::new(&format!("{}/README.md", project_path)).exists() {
        coverage += 20;
    }
    
    if Path::new(&format!("{}/docs", project_path)).exists() {
        coverage += 15;
    }
    
    Ok(coverage.min(100))
}

fn estimate_tech_debt(project_path: &str) -> std::result::Result<String, String> {
    let large_files = find_large_files(project_path)?;
    let debt_level = large_files.len();
    
    let debt_description = match debt_level {
        0..=2 => "Low",
        3..=5 => "Medium", 
        6..=10 => "High",
        _ => "Critical",
    };
    
    Ok(debt_description.to_string())
}

fn should_skip_directory(dir_name: &str) -> bool {
    matches!(dir_name, "node_modules" | "target" | ".git" | ".idea" | ".vscode" | "dist" | "build")
}

fn is_important_file(filename: &str) -> bool {
    filename.ends_with(".rs") || filename.ends_with(".toml") || 
    filename.ends_with(".md") || filename.ends_with(".json") ||
    filename == "Cargo.toml" || filename == "README.md"
}

fn is_code_file(ext: &str) -> bool {
    matches!(ext, "rs" | "js" | "ts" | "py" | "java" | "cpp" | "c" | "h" | "go" | "rb" | "php")
} 